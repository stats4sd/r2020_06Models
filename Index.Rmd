---
title: "Introduction to Statistical Modelling in R"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    df_print: default
runtime: shiny_prerendered
description: >
  Modelling in R
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(ggfortify)
library(learnr)
library(broom)
library(knitr)
library(Lock5Data)
library(emmeans)

predict_data<-data.frame(Years=1:6)
predict_data2<-expand.grid(Years=c(8,10,12,14),Hipp=c(5000,5500,6000,6500,7000))
predict_data_stupid<-data.frame(Years=5000,Hipp=10)

tutorial_options(exercise.timelimit = 10)
FootballBrain<-Lock5Data::FootballBrain


cog_yr_model<-lm(Cogniton~Years,data=FootballBrain)
linreg_mod<-lm(Hipp~Years,data=FootballBrain)
anova_mod<-lm(Hipp~Group,data=FootballBrain)
multreg_mod<-lm(Cogniton~Years+Hipp,data=FootballBrain)
multreg_mod_interaction<-lm(Cogniton~Years*Hipp,data=FootballBrain)
```


## Introduction 

In this workbook we will introduce you to the modeling syntax and functions contained within R. We will focus on the `lm` function, and show how this can do much more than just a simple linear regression!

We will also introduce a some useful packages to make modeling in R a little bit easier, and more compatible with a tidy workflow - including `broom` and `emmeans`.

We are assuming that you have come across the topic of linear models before. Even if you have, there is a nice video from Crash Course Statistics [here](https://www.youtube.com/watch?v=WWqE7YHR4Jc) which provides a nice refresher of the methodology.


## Data used in this session

The data used for this session is taken from a 2014 study into the impact of playing American Football on brain damage. It has been imported into this session as a data frame called `FootballBrain`.


Data from 75 individuals is available, a mixture of football players with known skull or concussion injuries, football players without known skull or concussion injuries and non-football players; made up of a similar demographic profile to football players. Which of these three groups an individual is part of is shown in the `Group` variable. Other data available is shown below.

```{r,echo=FALSE}
data.frame(Variable=colnames(FootballBrain),
           Explanation=c("Group (explained above)","Total hippocampus volume, in microL",
                         "Left hippocampus volume, in microL","	Number of years playing football","Cognitive testing composite reaction time score, given as a percentile")) %>% kable()
```

You can explore this data a little below:


```{r,eacho=FALSE}
DT::datatable(FootballBrain)
```

Reference for the data:
Singh R, Meier T, Kuplicki R, Savitz J, et al., "Relationship of Collegiate Football Experience and Concussion With Hippocampal Volume and Cognitive Outcome," JAMA, 311(18), 2014

## Simple linear regression

### Exploring the Data

Let's first of all investigate our data, to take a look at the relationship between hippocampus volume and number of years playing football. Both of these are numeric variables so we can use a point geometry within ggplot2.


```{r ggplot1,exercise=TRUE}
ggplot(data=FootballBrain,aes(y=Hipp,x=Years))+
  geom_point()
```


Looking at this graph, we can see a pretty clear trend - as number of years is increasing the hippocampus volume is decreasing. Because of the way the data is collected we should not be surprised to see the jump from individuals with 0 years experience (the non-footballers) to those with 6 years experience or more (the football players).

A way of summarising this trend, with numbers, could be to break the explanatory variable into groups and then calculate mean values within those new groups. How to split into groups is a little arbitrary, but we could select 0-4 years, 5-9 years, 10-14 years, 15+ years. To do this we could use the `cut` function within `mutate` to create a new variable.

```{r cut1, exercise=TRUE}
FootballBrain %>%
  mutate(Year_grp=cut(Years,breaks=c(-0.5,4.5,9.5,14.5,99),
                      labels=c("0-4 years", "5-9 years", "10-14 years", "15+ years")))
```

Within the `cut` function we need to provide  `breaks` denoting which values make up the boundaries for the new groups we are creating and `labels` providing the names for the new groups. 

It can sometimes be tricky to work out the logic of how the groups split when dealing with integer data like we have here. e.g. with breaks of `c(0,10,20)` - would the value of 10 be in the first or second group? And would the value of 0 be used at all? You can find this out from the help menu, but a shortcut to save yourself worrying about this is to use decimal values between the integers like I have above. This way you can probably be more confident in how the groups are defined! 

One we have this new variable we can `group_by` and `summarise` as we have seen before.

```{r cut2,exercise=TRUE}
FootballBrain %>%
  mutate(Year_grp=cut(Years,breaks=c(-0.5,4.5,9.5,14.5,99),
                      labels=c("0-4 years", "5-9 years", "10-14 years", "15+ years"))) %>%
    group_by(Year_grp) %>%
      summarise(mean(Hipp))


```

This now gives a clear summary of how the mean hippocampus volume is decreasing with the increase in number of years of playing football.

### Correlation


A simple way of summarising this relationship, that you probably learnt in school, could be through calculating the correlation coefficient. This has a nice easy function in R called cor(). This requires the names of two columns of numeric data to determine the correlation coefficient.

```{r cor0,exercise=TRUE}
cor(FootballBrain$Hipp,FootballBrain$Years)
```

The correlation is pretty strong, -0.69, - as we might expect from looking at the plot. It is negative, because hippocampus volume is decreasing with an increase in years. 
But correlation coefficent is a very limited type of analysis - we can learn much more through using a modeling approach.

You probably learnt at school about the idea of 'putting a line through' your points when you see a scatter point like this. We have already learnt about `geom_smooth`, but as discussed previously it defaults to a moving average type model. However we can change the `method` argument to fit a simple straight line instead. Looking at the plot, a straight line does like a reasonable choice for modelling this data.

```{r plotlm,exercise=TRUE}
ggplot(data=FootballBrain,aes(y=Hipp,x=Years))+
  geom_point()+
    geom_smooth(method="lm")
```
By default we see a 95% confidence interval shaded around the trend line.

### Fitting the Model

To examine what we actually have in our model, we need to fit the model ourself. We do this using the lm() command. The syntax for this is very similar to what we saw in the previous module for t-tests, with a response variable, a tilde, then the explanatory variable. Like with the t.test function the data argument comes second, after the formula. 

```{r mdo1,exercise=TRUE}
lm(Hipp~Years,data=FootballBrain)
```

The output by default only tells us two things:
"Call" - simply repeating back the model we have specified
"Coefficients": Telling us the values of the parameters

A linear regression follows the equation of a straight line y = B0 + B1x (you may have learnt this as y=a+bx or y=mx+c ; depending on where and when you were about 12 years old)
The coefficients give us the value of our intercept: 7599 and the value of our slope: -130 So the overall model would be:

Hippocampus Volume (microL)  = 7599  - 130*Years playing football

The value of the intercept is interpreted as the expected value of the response variable, where all explanatory variables are equal to zero. So for someone with no years of football, we would expect to see a hippocampus volume of 5799 microL.

The value of the slope represents the change we expect to see in the response variable for a one unit increase in the explanatory variable. So for every year of increased football playing, we expect a reduction of the hippocampus volume of 130 microL


However we can get much more information from our model than this! But first we need to save the model to an object:

```{r mod_obj,exercise=TRUE}
linreg_mod<-lm(Hipp~Years,data=FootballBrain)

```

As ever, when creating an object we dont see any immediate output. But we now have the ability to use lots of functions that give us different pieces of output and inference from this model. R is a little different from many other software packages, which will produce a lot of different outputs when you create a model. In R you have to ask specifically for what you want out of a model.

### Summarising the model

```{r summary,exercise=TRUE}
summary(linreg_mod)
```

`summary(model)` provides us with a lot of useful information - model fit statistics (R squared values & F statistic), standard errors and p-values for the coefficients.

The `broom` library also provides the functions `glance` and `tidy`. This extracts similar information to `summary` but returns it in the form of data frames. This can be very useful if we want to export results from this model into other analyses or to make the output look nice in our reports. 

```{r glance0,exercise=TRUE}
glance(linreg_mod)
```

```{r tidy,exercise=TRUE}
tidy(linreg_mod)
```
In general - `summary` is useful if all you want to do is look at the model output; the output is designed to be easier for humans to read. `glance` and `tidy` are better if you want to use that model output in some way; the output is designed to be easier for computers to read.


Overall the information tells us that the relationship between the Years playing football and hippocampus volume is highly significant. p=1.05e-11. i.e. p=0.00000000001.

The intercept is also significant. But this is almost certainly not of interest. The null hypothesis which generates this p-value is that the intercept is equal to 0. In this case that would mean that for someone who had never played football the hippocampus volume is zero (i.e. they literally have no brain). It is not really suprising to see very strong evidence against this nonsensical null hypothesis! 

We can also see that 47% of the variability in hippocampus volume can be explained by the linear increase in number of years playing football (R- Squared). You can read a little bit about some of the various model fit statistics, and what they are used for here.

We have actually seen this 47% number before (sort of). Look at the square root of this number:

```{r sqrt1,exercise=TRUE}
sqrt(0.4713346)
```

*Where have you seen this number before?*

Maybe you remember it from here:
```{r cor2,exercise=TRUE}
cor(FootballBrain$Hipp,FootballBrain$Years)
```
The R Squared value from a simple linear model like this is equal to the correlation coefficient squared.

There are also other model fit statistics in the output (AIC, BIC, Deviance) which could be used when comparing between different models from this same data.

confint() will give 95% confidence intervals around the parameters:

```{r ci1,exercise=TRUE}
confint(linreg_mod)
```

So that we can see that our 95% confidence interval around the average decrease in the hippocampus volume by year of football goes from -162 to -97. As before, we should probably ignore the numbers for the intercept in this model

### Checking Model

We should also check our model fit plots to assess model validity.
```autoplot(model)``` from the ggfortify package produces 4 model checking plots. 

```{r check_res,exercise=TRUE}
autoplot(linreg_mod)
```

Do these plots look OK? What are we actually looking for here?

It is worth recapping, or learning how to interpret these plots: https://statisticsbyjim.com/regression/ols-linear-regression-assumptions/

In this case, most of the plots look fine - there are no major outliers, non-linear trends, deviation from normality or high leverage points. 

There is some evidence of an increase in variability with increasing predicted value. But this is not a major deviation - the trend line being drawn on the scale location plot perhaps looks worse than it should, because of how well predicted the two lowest values in the data were.

There are several things we could do to try to improve our model, in cases where these residual plots show problems:

Add covariates. This may help explain non-linear patterns or the existence of outliers. 
Remove outliers and conduct sensitivity analysis. This will help us understand the impact of the outliers on our conclusions.
Transform variables. Different transformations may help improve a model non-linear relationships, or heterogeneity, or the normality assumptions.
With severe violations of normality or heterogeneity we may consider using a generalised linear model, making a different distributional assumption about our residuals. or transforming our variable.

### Making predictions

Remember in our original data we had nobody who had between 1 and 6 years of football experience. If we are happy with our model validity then we can also make predictions about what we would expect the average hippocampus volume to be for footballers with that level of experience.

To make predictions we first need to create a new data frame containing the values we want to predict. In this example we just have one explanatory variable, but we need to make sure that the prediction data frame contains all the explanatory variables from the model.

```{r prd_data,exercise=TRUE}
predict_data<-data.frame(Years=1:6)
predict_data
```


We can either use the function `predict` or `augment`. `predict` is the standard function from base-R, which will return just the predicted values. But i prefer the `augment` function from the `broom` library which adds the predictions into the existing data frame. You can see the difference below.

```{r aug_pred,exercise=TRUE}

augment(linreg_mod,newdata=predict_data)

predict(linreg_mod,newdata=predict_data)



```

You can see the fitted values are the same from both functions, but the output from `augment` returns the predictions in a more useable format. For example we might want to add these onto the plot we made earlier. 

```{r pred_plot,exercise=TRUE}
predict_data<-augment(linreg_mod,newdata=predict_data)

ggplot(data=FootballBrain,aes(y=Hipp,x=Years))+
  geom_point()+
      geom_point(data=predict_data,aes(y=.fitted,x=Years),inherit.aes = FALSE,color="red",size=4)
      
```

This is not really a modelling point, since drawing the line with `geom_smooth` is a better way of showing the same information. But it is useful to know that in ggplot, you can set custom data sets to be used within each geometry! You are able to specify a different set of data and aesthetics within any geometry, as long as you also include the argument `inherit.aes=FALSE`.


## Multiple linear regression

I am now going to change my question slightly, and look at the `Cogniton` variable, related to brain function rather than brain size. A value of 100 here indicates a respondent was in the top percentile for reaction times, so the higher the value the better the brain function. Note that this variable is only collected for the football players, it is not collected (and NA in the data) for those with 0 years of playing football. 

I may be interested now in both whether there is a link between `Hipp` and `Cognition`, (does brain size affect brain function) but also about whether there is a link between `Years` and `Cognition` (does increased football playing affect brain function).

### Seperate Models?

We could go through the process as before, with separate models for each of these two questions. As a recap - let's do some of these steps now.

Below I have produced a plot, and fitted a model, showing how cognitive ability is related to number of years playing football.


```{r,echo=FALSE}
ggplot(data=FootballBrain,aes(y=Cogniton,x=Years))+
  geom_point()+
    geom_smooth(method="lm")
```


```{r,echo=FALSE}
cog_yr_model<-lm(Cogniton~Years,data=FootballBrain)
summary(cog_yr_model)
```

*Now it is your turn. Make a plot showing the relationship between Hippocampus size, `Hipp`, and Cognitive function, `Cogniton`. Add a linear trend line onto this plot*
```{r CogHip1,exercise=TRUE}

```

```{r CogHip1-solution}
ggplot(data=FootballBrain,aes(y=Cogniton,x=Hipp))+
  geom_point()+
    geom_smooth(method="lm")
```

*Now fit and summarise the results from a linear model for the relationship between `Cogniton`, as the response variable and `Hipp` as the explanatory variable.*
```{r CogHip2,exercise=TRUE}

```


```{r CogHip2-solution}

cog_hip_model<-lm(Cogniton~Hipp,data=FootballBrain)

summary(cog_hip_model)
#or
tidy(cog_hip_model)
glance(cog_hip_model)

```

From our results we can conclude that both hippocampus size and number of years playing football have a significant linear relationship with cognitive function. 

### Combined model

However, these variables do not all exist in isolation. And we have already seen in the previous example how `Years` and `Hipp` are related to each other. So to get a better idea of how the relationship works, we want to consider a regression model which accounts for both variables.

Luckily in R this is easy! We just add a `+` between the variables.


```{r multiple, exercise=TRUE}
multreg_mod<-lm(Cogniton~Years+Hipp,data=FootballBrain)
summary(multreg_mod)
```
The coefficients from a multiple regression model have a slightly different interpretation to in a single variable model. The coefficient for `Years`, -0.61, is now interpreted as the expected change in the outcome, `Cogniton`, for a one unit increase *when holding the value of `Hipp` constant*. We see that this effect is not statistically significant, p=0.619. This would suggest that years playing football does not have an effect upon the brain function, after controlling for hippocampus volume.

But we can see an indirect effect through hippocampus volume. Increased football playing is associated with decreased brain volume; and decreased hippocampus volume is associated with cognitive function. Scientifically, this relationship pathway would also seem to make sense. 


### Interactions

We could also consider if there was an interaction between `Years` and `Hipp`. This would help us to determine, for example, if there was only an effect of `Years` on `Cogniton` among people with high hippocampus volume, and no effect among people with lower hippocampus volume. 

We can fit an interaction between variables by using a `*` rather than a `+`.

```{r intereaction_term, exercise=TRUE}
multreg_mod_interaction<-lm(Cogniton~Years*Hipp,data=FootballBrain)
summary(multreg_mod_interaction)
```
In this model we can now see that none of our model terms are statistically significant. However the overall model is highly significant, from the F-test at the bottom of the output, and the R square value is quite high. So why has this happened? It is likely we have run into an issue of over-fitting the model. 

### Goodness-of-fit statistics

This can commonly happen when we have small datasets, lots of variables, or highly correlated explanatory variables. In this case we have two of those problems - a fairly small dataset and highly correlated explanatory variables. When we have an over-fitted model it is likely that the inferences made from it will not generalise into a wider population, and would only be applicable to the specific data that we have collected. 

We can see further evidence of this by looking more at the model-fit statistics we have seen previously from `glance()`. In particular the AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion). 

```{r glance, exercise=TRUE}
glance(multreg_mod)
glance(multreg_mod_interaction)

```
If we just wanted the AIC or BIC values, and no other output, there are the standalone functions `AIC()` and `BIC()`, which just need the name of the model as the input.

When comparing models from the same data, we are looking for lower values of AIC and BIC, which will indicate a better model fit. From the output both the AIC and BIC are larger for the model containing the interaction variable than the model without the interaction, indicating the model without the interaction should be preferred. 

You can read more about these goodness-of-fit statistics [here](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118856406.app5). 

So in this case, we should drop the interaction term and revert back to the previous model, since it is non-significant and also impacting on our ability to make inferences from the other model terms.

### Checking residuals

Many of the additional functions we can run on the model are all the same as we have seen previously. `autoplot`, from the `ggfortify` package, can be used to check the residuals:

```{r ap2, exercise=TRUE}
autoplot(multreg_mod)
```
No major issues within these plots to worry about. There are small deviations from linearity and homogeneity being indicated in the top left and bottom left plots, in both we can see a slight trend in the fitted line rather than a horizontal line. But these do not look large enough deviations to be majorly problematic.

### Making predictions

We can also use `augment` to make predictions as before. This is particularly useful when considering the marginal effects of each variable, or in cases where we do have an interaction.
The data we predict over has to contain all variables in the data. Remember that we could ask R for predictions about any value of `Years` or `Hipp`. No error will appear if we mistakenly ask for a prediction of someone who has been playing football for 5000 years, and has a hippocampus volume of 10 microL. Although the standard error of that prediction will be very large. 

```{r stupidpred,example=TRUE}
predict_data_stupid<-data.frame(Years=5000,Hipp=10)

augment(multreg_mod,newdata=predict_data_stupid)

```
Since the possible range of `Cogniton` is 0-100, having a predicted value of -3125 is obviously nonsense! So hopefully, as long as we were thinking about what we were doing, we would notice this mistake.

Make sure you consider if the predictions are sensible - extrapolating outside the range of our data is always dangerous!

The function `expand.grid` is a useful function to use when dealing with multiple regression models. This will give us all combinations of the variables we provide. For example, in the chunk below we provide four different values for `Years` and five different values for `Hipp`. The resulting dataset will have 20 rows - one row for each combination.


Once we have this dataset from `expand.grid()` we can use `augment()`in the same way we saw before. 

```{r preds,example=TRUE}
predict_data2<-expand.grid(Years=c(8,10,12,14),Hipp=c(5000,5500,6000,6500,7000))

augment(multreg_mod,newdata=predict_data2)

```

If we look into the data we can see that, comparing within the same hippocampus volume, there is only a small difference as we increase the number of years of football playing. But comparing within the same number of years we see a very large difference in the fitted values as we increase hippocampus volume.

This is not that easy to spot from just staring at some numbers though. This is a good time to make a plot!

We can pipe from the `augment` function into ggplot, and the produce a plot with one of our variables on the x axis, and another variable mapped to a colour aesthetic so that multiple lines are drawn for each value.

However we might get a slightly unexpected output from this:

```{r intplot, exercise=TRUE}
augment(multreg_mod,newdata=predict_data2) %>%
  ggplot(aes(y=.fitted,x=Hipp,col=Years))+
    geom_line()
```
Where we map a numeric variable to the `colour` aesthetic it does not, by default, create seperate lines for each value of that variable. There are two ways we can solve this - either by also including a `group` aesthetic, which will force a split for every unique value. Or by converting the variable into a factor variable. The only difference in the output of these approaches is the colour palette, which has different defaults for numeric variables than for categorical variables. 

```{r intplot2,exercise=TRUE}
augment(multreg_mod,newdata=predict_data2) %>%
  ggplot(aes(y=.fitted,x=Hipp,col=Years,group=Years))+
    geom_line()

augment(multreg_mod,newdata=predict_data2) %>%
  ggplot(aes(y=.fitted,x=Hipp,col=factor(Years)))+
    geom_line()

```
This clearly shows how small the `Years` effect is in comparison to the `Hipp` effect. We could also flip around the variables, and include `Years` on the x axis, with multiple lines for `Hipp`.


*Produce a similar plot, but now with the `Years` variable on the x axis and multiple lines based on the `Hipp` variable*
```{r flipit,exercise=TRUE}

```

```{r flipit-solution}
augment(multreg_mod,newdata=predict_data2) %>%
  ggplot(aes(y=.fitted,x=Years,col=factor(Hipp)))+
    geom_line()
```


## Analysis of Variance

If we think back to the original dataset, as well as the number of years of football playing, we also had a categorical variable, `Group`, which indicated if participants in this survey had known concussion injuries, no known concussion injuries or were in the control group (no football playing).


### Exploratory analysis

When exploring this relationship, we may want to look at violin plots or boxplots, rather than using a scatter plot.

```{r box1,exercise=TRUE}
ggplot(data=FootballBrain,aes(y=Hipp,x=Group))+
  geom_boxplot()
```
As expected from our previous analyses the control group clearly have larger hippocampus volumes than either of the other two groups. Comparing the concussion group with the non-concussion group of footballers, we also see that the average volume is lower among the concussion group. 

We can also calculate summary statistics in a more straightforward way for grouped data, simply using group_by and summarise as we have done previously.

**Calculate the mean, median and standard deviation of `Hipp` by `Group`**
```{r sumstats1,exercise=TRUE}

```

```{r sumstats1-solution}
FootballBrain %>%
  group_by(Group) %>%
    summarise(mean=mean(Hipp),median=median(Hipp),sd=sd(Hipp))

```

### Fitting the model


Instead of "linear regression" the statistical method we might use here is often called "analysis of variance". However, mathematically and in terms of how R treats them, these are the same. The only difference being with "linear regression" our explanatory variable is numeric, and in "analysis of variance" our explanatory variable is a factor.

Do be careful with the format of your data - particular if you are using codes for groups. I explain the potential problems that can arise here.

So we can use the `lm`, `summary`, `glance`, `tidy`, `autoplot` functions exactly as we have seen before, should we so wish.

```{r}
anova_mod<-lm(Hipp~Group,FootballBrain)

summary(anova_mod)
glance(anova_mod)
tidy(anova_mod)
autoplot(anova_mod)


```

The output from `glance` and `autoplot` is interpreted in the same way as we have seen previously. Consider for yourself whether the residual plots suggest any problems with this model, and compare the AIC and BIC values back against the results from the linear regression model to see which would be considered a better fit for the data.

The output from `summary` or `tidy` is a little different to intepret though. Even though we only have one variable, `Group`, we see two coefficients and two p-values for this variable. And, if we think of our group variable, we only see two of the three groups represented in the output. The control group appears to be missing.

When we have a categorical variable the intercept term represents the reference level of that variable. By default the reference level will be the first group alphabetically. In this case that is the `Control` group, which is probably a sensible choice to use as the reference level. But we could change the reference level by using the `relevel()` function within a call to `mutate()`.

Here the intercept, 7602, is therefore the expected value of hippocampus volume within that `Control` group. If you look back to the summary statistics you created just a few chunks above, this number should look familiar!

The other coefficients represent the difference between each group and the reference level. So the `FBConcuss` group have an expected hippocampus volume which is 1868 microL lower than the `Control` group; and the `FBNoConcuss` group have a volume 1143 microL lower than the control group. 

The t value and p-value associated with those terms are also in relation to the comparison of each group to the control group. This output shows us that both the `FBConcuss` and `FBNoConcuss` groups have  significantly lower hippocampus volumes than the `Control` group.

What we can't see from this output is:
1. Whether the `Group` variable has an overall significant effect. Although it is fairly clear that it does, but it might be nice to obtain a formal confirmation of this.
2. Whether there is a significant difference between the `FBConcuss` and `FBNoConcuss` groups

### Analysis of variance table

To find whether the `Group` variable has an overall significant effect, we would usually take a look at the analysis of variance table using the `anova` function. Note that this table is useful to look at, not just for "Analysis of Variance", but in any model which has multiple terms. This table partitions the overall variance into each of the variables, and identifies which variables have significant effects.

```{r anovatab,exercise=TRUE}
anova(anova_mod)
```
Unsurprisingly group has, overall, a highly significant effect.
If you have learnt about analysis of variance tables before, you may know there are quite a few different methods of breaking down the overall variance and calculating p-values, sometimes known as "Type I", "Type II", "Type III". 

By default R produces the Type I (Sequential) sum of squares. Many other statistical software packages default to Type III, so this is often a cause of confusion when comparing results between software. If you would like Types II or III, there is a function `Anova()` (capital A!) from the `car` library.

You can read more about this [here](http://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html).

### Post-hoc comparisons

When we want to investigate hypotheses from our model, which are not included in the direct output, like whether there is difference between `FBConcuss` and `FBNoConcuss` groups, this is known as a post-hoc test.

The `emmeans` library makes it easy to perform these post-hoc tests, and also contains some nice functions for helping to easily visualise interactions between categorical variables within models.

We would firstly pipe from the model into the functions `emmeans`. The first argument needed for `emmeans` is the model, but as we are using the pipe we do not need to specify this. Yes, we can also pipe, not just from data, but also from a model - as long as the first argument that the subsequent function requires is to have a model.

The second argument is then the tilde followed by the categorical variable we wish to make inferences about, in this case `Group`.

```{r emm1, exercise=TRUE}
anova_mod %>%
emmeans(~Group) 
```
From this model, the output at this stage is not especially useful, since we already have the mean values calculate from earlier. Although if we want a really quick and easy plot of the mean values, with the 95% confidence interval we can pipe from this into a very simple function `plot`.

```{r emm2, exercise=TRUE}
anova_mod %>%
emmeans(~Group) %>%
  plot()
```

But this function is extremely powerful if we have more complex models, with multiple variables, as it allows us to isolate the marginal effect of individual variables. `emmeans` stands for "*e*stimated *m*arginal means". Unlike `predict` or `augment` which require us to provide values for all variables within the model, `emmeans` allows us to specify a subset of one or more terms and it will adjust for average values of the remaining variables. You can read more about `emmeans` [here](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html)

As well as providing these estimated marginal means, this package makes it easy to conduct post-hoc hypothesis tests. The simplest of these tests, and the one we are interested in here, would be to compare all of the pairwise combinations of a categorical variable. We can do this by piping from `emmeans()` into the function `pairs()`.


```{r emm3, exercise=TRUE}
anova_mod %>%
  emmeans(~Group) %>%
    pairs()
```
This shows us that, as we have seen already, the control group has a significantly higher hippocampus volume than the two other groups. But it also shows us something new, that the concussion group has a significantly lower hippocampus volume than the non-concussion group.



## References 

Simple Linear Regression in R (Marin Stats Lectures): https://www.youtube.com/watch?v=66z_MRwtFJM
There are lots of subsequent videos on this channel about other statistical modelling techniques

An R Companion to Applied Regression
https://socialsciences.mcmaster.ca/jfox/Books/Companion/downloads.html

Linear Regression Tutorial: (UC Business Analytics R Programming Guide) https://uc-r.github.io/linear_regression

Common statistical tests are linear models (Jonas Lindel√∏v):
https://lindeloev.github.io/tests-as-linear/

When to use regression Analysis (Statistics by Jim): https://statisticsbyjim.com/regression/when-use-regression-analysis/

